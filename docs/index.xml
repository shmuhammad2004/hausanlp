<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>HausaNLP Research Group</title>
    <link>https://hausanlp.github.io/</link>
      <atom:link href="https://hausanlp.github.io/index.xml" rel="self" type="application/rss+xml" />
    <description>HausaNLP Research Group</description>
    <generator>Wowchemy (https://wowchemy.com)</generator><language>en-us</language><copyright>© HausaNLP Research Group. Maintained by Shamsuddeen Muhammad</copyright><lastBuildDate>Sat, 09 Jan 2021 00:00:00 +0000</lastBuildDate>
    <image>
      <url>https://hausanlp.github.io/images/icon_hua2ec155b4296a9c9791d015323e16eb5_11927_512x512_fill_lanczos_center_2.png</url>
      <title>HausaNLP Research Group</title>
      <link>https://hausanlp.github.io/</link>
    </image>
    
    <item>
      <title>How to Tidy Messy Data  Part 1)</title>
      <link>https://hausanlp.github.io/post/tidying-messy-data/</link>
      <pubDate>Sat, 09 Jan 2021 00:00:00 +0000</pubDate>
      <guid>https://hausanlp.github.io/post/tidying-messy-data/</guid>
      <description>
&lt;script src=&#34;index_files/header-attrs/header-attrs.js&#34;&gt;&lt;/script&gt;


&lt;p&gt;Data scientist often spent about 80% of data analysis process on cleaning and preparing data&lt;a href=&#34;#fn1&#34; class=&#34;footnote-ref&#34; id=&#34;fnref1&#34;&gt;&lt;sup&gt;1&lt;/sup&gt;&lt;/a&gt;. Worst still, cleaning and preparing the data is an iterative process. Hadley Wickham refer to this process of cleaning and preparing data as &lt;strong&gt;data tidying&lt;/strong&gt;: structuring datasets to facilitate analysis. Therefore, it is very important to get the right tool to efficiently and quickly tidy any messy data and spend more time working on your analysis.&lt;/p&gt;
&lt;center&gt;
&lt;img src=&#34;tidydata.png&#34; title=&#34;fig:&#34; alt=&#34;Tidydata&#34; /&gt;
&lt;/center&gt;
&lt;p&gt;I mostly use Python for machine learning. But R is an exceptional tool for data manipulation, data visualization, and data analysis due to the many available packages in R developed mainly for data analysis. R is becoming the “de facto best tool” for data analysis. Therefore, we will use R to explore different ways to tidy data. In this part 1 series, we will gently start by exploring the &lt;code&gt;Janitor&lt;/code&gt;&lt;a href=&#34;#fn2&#34; class=&#34;footnote-ref&#34; id=&#34;fnref2&#34;&gt;&lt;sup&gt;2&lt;/sup&gt;&lt;/a&gt; package and see how it makes tidying data easy. In subsequent series, we will explore &lt;code&gt;dplyr&lt;/code&gt;&lt;a href=&#34;#fn3&#34; class=&#34;footnote-ref&#34; id=&#34;fnref3&#34;&gt;&lt;sup&gt;3&lt;/sup&gt;&lt;/a&gt; and &lt;code&gt;tidyr&lt;/code&gt;&lt;a href=&#34;#fn4&#34; class=&#34;footnote-ref&#34; id=&#34;fnref4&#34;&gt;&lt;sup&gt;4&lt;/sup&gt;&lt;/a&gt; packages which are the most complete packages for data manipulaton and tidying data.&lt;/p&gt;
&lt;center&gt;
&lt;img src=&#34;rpython.jpg&#34; title=&#34;fig:&#34; alt=&#34;R Vs Python&#34; /&gt;
&lt;/center&gt;
&lt;div id=&#34;janitor-package&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Janitor Package&lt;/h2&gt;
&lt;p&gt;The janitor package has user-friendly functions for tidying messy data. It provides functions for formating column names, detecting duplicate records, provide quick tabulations, and many more.&lt;/p&gt;
&lt;p&gt;For the purpose of this series, we are going to use a &lt;a href=&#34;https://github.com/BrunoGrandePhD/2020-11-14-rladies-workshop/blob/main/learnr-tutorial/messy_penguins.cs&#34;&gt;pinguin dataset&lt;/a&gt; that has been deliberately messed.&lt;/p&gt;
&lt;p&gt;Loading the required packages&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;library(janitor)                                                     # CRAN v2.1.0
library(tidyverse)                                                   # CRAN v1.3.0&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Loading the dataset from &lt;a href=&#34;%22https://raw.githubusercontent.com/BrunoGrandePhD/2020-11-14-rladies-workshop/rladies-tunis/learnr-tutorial/messy_penguins.csv&#34;&gt;Github&lt;/a&gt;.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;messy_penguins &amp;lt;- read_csv(&amp;quot;https://raw.githubusercontent.com/BrunoGrandePhD/2020-11-14-rladies-workshop/rladies-tunis/learnr-tutorial/messy_penguins.csv&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Observing the data&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;glimpse(messy_penguins)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## Rows: 344
## Columns: 18
## $ studyName             &amp;lt;chr&amp;gt; &amp;quot;PAL0708&amp;quot;, &amp;quot;PAL0708&amp;quot;, &amp;quot;PAL0708&amp;quot;, &amp;quot;PAL0708&amp;quot;, &amp;quot;PA…
## $ `Sample Number`       &amp;lt;dbl&amp;gt; 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, …
## $ Species               &amp;lt;chr&amp;gt; &amp;quot;Adelie Penguin (Pygoscelis adeliae)&amp;quot;, NA, NA, …
## $ Region                &amp;lt;chr&amp;gt; &amp;quot;Anvers&amp;quot;, &amp;quot;Anvers&amp;quot;, &amp;quot;Anvers&amp;quot;, &amp;quot;Anvers&amp;quot;, &amp;quot;Anvers…
## $ Island                &amp;lt;chr&amp;gt; NA, NA, &amp;quot;Torgersen&amp;quot;, NA, NA, NA, NA, NA, NA, NA…
## $ Stage                 &amp;lt;chr&amp;gt; &amp;quot;Adult, 2 Egg Stage&amp;quot;, &amp;quot;Adult, 1 Egg Stage&amp;quot;, &amp;quot;Ju…
## $ `Individual ID`       &amp;lt;chr&amp;gt; &amp;quot;N1A1&amp;quot;, &amp;quot;N1A2&amp;quot;, &amp;quot;N2A1&amp;quot;, &amp;quot;N2A2&amp;quot;, &amp;quot;N3A1&amp;quot;, &amp;quot;N3A2&amp;quot;,…
## $ `Clutch Completion`   &amp;lt;chr&amp;gt; &amp;quot;Yes&amp;quot;, &amp;quot;Yes&amp;quot;, &amp;quot;Yes&amp;quot;, &amp;quot;Yes&amp;quot;, &amp;quot;Yes&amp;quot;, &amp;quot;Yes&amp;quot;, &amp;quot;No&amp;quot;,…
## $ `Date Egg`            &amp;lt;chr&amp;gt; &amp;quot;11/11/07&amp;quot;, &amp;quot;11/11/07&amp;quot;, &amp;quot;11/16/07&amp;quot;, &amp;quot;11/16/07&amp;quot;,…
## $ `Culmen Length (mm)`  &amp;lt;chr&amp;gt; &amp;quot;39.1&amp;quot;, &amp;quot;39.5&amp;quot;, &amp;quot;40.3&amp;quot;, NA, &amp;quot;36.7&amp;quot;, &amp;quot;39.3&amp;quot;, &amp;quot;38…
## $ Nickname              &amp;lt;chr&amp;gt; &amp;quot;Kamile&amp;quot;, &amp;quot;Dixie&amp;quot;, &amp;quot;Arian&amp;quot;, &amp;quot;Alexander&amp;quot;, &amp;quot;Dewi&amp;quot;…
## $ `Culmen Depth (mm)`   &amp;lt;chr&amp;gt; &amp;quot;18.7&amp;quot;, &amp;quot;17.4&amp;quot;, &amp;quot;18&amp;quot;, &amp;quot;-&amp;quot;, &amp;quot;19.3&amp;quot;, &amp;quot;20.6&amp;quot;, &amp;quot;17.…
## $ `Flipper Length (mm)` &amp;lt;chr&amp;gt; &amp;quot;181&amp;quot;, &amp;quot;186&amp;quot;, &amp;quot;195&amp;quot;, &amp;quot;--&amp;quot;, &amp;quot;193&amp;quot;, &amp;quot;190&amp;quot;, &amp;quot;181&amp;quot;,…
## $ `Body Mass`           &amp;lt;chr&amp;gt; &amp;quot;3750 g&amp;quot;, &amp;quot;3800g&amp;quot;, &amp;quot;3250&amp;quot;, NA, &amp;quot;3450 grams&amp;quot;, &amp;quot;3…
## $ Sex                   &amp;lt;chr&amp;gt; &amp;quot;M&amp;quot;, &amp;quot;FEMALE&amp;quot;, &amp;quot;FEMALE&amp;quot;, NA, &amp;quot;FEMALE&amp;quot;, &amp;quot;MALE&amp;quot;, …
## $ `Delta 15 N (o/oo)`   &amp;lt;chr&amp;gt; NA, &amp;quot;8.94956&amp;quot;, &amp;quot;8.36821&amp;quot;, NA, &amp;quot;8.76651&amp;quot;, &amp;quot;8.664…
## $ `Delta 13 C (o/oo)`   &amp;lt;chr&amp;gt; NA, &amp;quot;-24.69454&amp;quot;, &amp;quot;-25.33302&amp;quot;, NA, &amp;quot;-25.32426&amp;quot;, …
## $ Comments              &amp;lt;chr&amp;gt; &amp;quot;Not enough blood for isotopes.&amp;quot;, NA, NA, &amp;quot;Adul…&lt;/code&gt;&lt;/pre&gt;
&lt;div id=&#34;clean_names-function&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;&lt;code&gt;clean_names()&lt;/code&gt; function&lt;/h3&gt;
&lt;p&gt;The &lt;code&gt;clean_names()&lt;/code&gt; handles problematic variable names, returning only lowercase letters with underscore as separator, appends numbers to duplicated names, andles special characters and spaces, and converts “%” to “percent” to retain meaning. clean_names() can only be use on dataframe like objects, other objects such as named lists and vectors, &lt;code&gt;make_clean_names()&lt;/code&gt; is used.&lt;/p&gt;
&lt;p&gt;Let us observe column names for our messy data&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;colnames(messy_penguins)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##  [1] &amp;quot;studyName&amp;quot;           &amp;quot;Sample Number&amp;quot;       &amp;quot;Species&amp;quot;            
##  [4] &amp;quot;Region&amp;quot;              &amp;quot;Island&amp;quot;              &amp;quot;Stage&amp;quot;              
##  [7] &amp;quot;Individual ID&amp;quot;       &amp;quot;Clutch Completion&amp;quot;   &amp;quot;Date Egg&amp;quot;           
## [10] &amp;quot;Culmen Length (mm)&amp;quot;  &amp;quot;Nickname&amp;quot;            &amp;quot;Culmen Depth (mm)&amp;quot;  
## [13] &amp;quot;Flipper Length (mm)&amp;quot; &amp;quot;Body Mass&amp;quot;           &amp;quot;Sex&amp;quot;                
## [16] &amp;quot;Delta 15 N (o/oo)&amp;quot;   &amp;quot;Delta 13 C (o/oo)&amp;quot;   &amp;quot;Comments&amp;quot;&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;We can see that, the column names structure is not uniform ( e.g “studyName”, “Sample Number”, “Delta 15 N (o/oo)”). So, to tidy these column names, we can use the &lt;code&gt;clean_names()&lt;/code&gt; function to change them to uniform structure.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;tidy_penguins &amp;lt;- clean_names(messy_penguins) 

colnames(tidy_penguins)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##  [1] &amp;quot;study_name&amp;quot;        &amp;quot;sample_number&amp;quot;     &amp;quot;species&amp;quot;          
##  [4] &amp;quot;region&amp;quot;            &amp;quot;island&amp;quot;            &amp;quot;stage&amp;quot;            
##  [7] &amp;quot;individual_id&amp;quot;     &amp;quot;clutch_completion&amp;quot; &amp;quot;date_egg&amp;quot;         
## [10] &amp;quot;culmen_length_mm&amp;quot;  &amp;quot;nickname&amp;quot;          &amp;quot;culmen_depth_mm&amp;quot;  
## [13] &amp;quot;flipper_length_mm&amp;quot; &amp;quot;body_mass&amp;quot;         &amp;quot;sex&amp;quot;              
## [16] &amp;quot;delta_15_n_o_oo&amp;quot;   &amp;quot;delta_13_c_o_oo&amp;quot;   &amp;quot;comments&amp;quot;&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Now, all the column names are change to lower-case and have consistent structure. By default, &lt;code&gt;clean_names()&lt;/code&gt; return snake-case like names, but you can specify other options such as the following cases:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;snake_case: “snake”&lt;/li&gt;
&lt;li&gt;lowerCamel: “lower_camel” or “small_camel”&lt;/li&gt;
&lt;li&gt;UpperCamel: “upper_camel” or “big_camel”&lt;/li&gt;
&lt;li&gt;ALL_CAPS: “all_caps” or “screaming_snake”&lt;/li&gt;
&lt;li&gt;lowerUPPER: “lower_upper”&lt;/li&gt;
&lt;li&gt;UPPERlower: “upper_lower”&lt;/li&gt;
&lt;li&gt;Sentence case: “sentence”&lt;/li&gt;
&lt;li&gt;Title Case: “title”&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;You can get details about any case &lt;a href=&#34;https://rdrr.io/cran/snakecase/man/to_any_case.html&#34;&gt;here&lt;/a&gt;&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;messy_penguins %&amp;gt;%  
  clean_names(case =&amp;quot;lower_camel&amp;quot;) %&amp;gt;% 
   colnames()&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##  [1] &amp;quot;studyName&amp;quot;        &amp;quot;sampleNumber&amp;quot;     &amp;quot;species&amp;quot;          &amp;quot;region&amp;quot;          
##  [5] &amp;quot;island&amp;quot;           &amp;quot;stage&amp;quot;            &amp;quot;individualId&amp;quot;     &amp;quot;clutchCompletion&amp;quot;
##  [9] &amp;quot;dateEgg&amp;quot;          &amp;quot;culmenLengthMm&amp;quot;   &amp;quot;nickname&amp;quot;         &amp;quot;culmenDepthMm&amp;quot;   
## [13] &amp;quot;flipperLengthMm&amp;quot;  &amp;quot;bodyMass&amp;quot;         &amp;quot;sex&amp;quot;              &amp;quot;delta15NOOo&amp;quot;     
## [17] &amp;quot;delta13COOo&amp;quot;      &amp;quot;comments&amp;quot;&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;To clean names, but leave some abbreviations to appear the way you want.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;messy_penguins %&amp;gt;% 
      clean_names(case = &amp;quot;lower_camel&amp;quot;,  abbreviations = c(&amp;quot;ID&amp;quot;, &amp;quot;N&amp;quot;, &amp;quot;mm&amp;quot;)) %&amp;gt;% 
     colnames()&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##  [1] &amp;quot;studyNAme&amp;quot;        &amp;quot;sampleNUmber&amp;quot;     &amp;quot;species&amp;quot;          &amp;quot;region&amp;quot;          
##  [5] &amp;quot;island&amp;quot;           &amp;quot;stage&amp;quot;            &amp;quot;individualID&amp;quot;     &amp;quot;clutchCompletion&amp;quot;
##  [9] &amp;quot;dateEgg&amp;quot;          &amp;quot;culmenLengthMm&amp;quot;   &amp;quot;nIckname&amp;quot;         &amp;quot;culmenDepthMm&amp;quot;   
## [13] &amp;quot;flipperLengthMm&amp;quot;  &amp;quot;bodyMass&amp;quot;         &amp;quot;sex&amp;quot;              &amp;quot;delta15NOOo&amp;quot;     
## [17] &amp;quot;delta13COOo&amp;quot;      &amp;quot;comments&amp;quot;&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;You can also restore column names to Title Case, e.g., for plotting&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;tidy_penguins %&amp;gt;%  
  clean_names( case = &amp;quot;title&amp;quot;) %&amp;gt;% 
   colnames()&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##  [1] &amp;quot;Study Name&amp;quot;        &amp;quot;Sample Number&amp;quot;     &amp;quot;Species&amp;quot;          
##  [4] &amp;quot;Region&amp;quot;            &amp;quot;Island&amp;quot;            &amp;quot;Stage&amp;quot;            
##  [7] &amp;quot;Individual Id&amp;quot;     &amp;quot;Clutch Completion&amp;quot; &amp;quot;Date Egg&amp;quot;         
## [10] &amp;quot;Culmen Length Mm&amp;quot;  &amp;quot;Nickname&amp;quot;          &amp;quot;Culmen Depth Mm&amp;quot;  
## [13] &amp;quot;Flipper Length Mm&amp;quot; &amp;quot;Body Mass&amp;quot;         &amp;quot;Sex&amp;quot;              
## [16] &amp;quot;Delta 15 n o Oo&amp;quot;   &amp;quot;Delta 13 c o Oo&amp;quot;   &amp;quot;Comments&amp;quot;&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;For vectors, we can use &lt;code&gt;make_clean_names&lt;/code&gt; functions.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;x &amp;lt;- structure(1:4, names = c(&amp;quot;This is first&amp;quot;, &amp;quot;this issecond&amp;quot;, &amp;quot;3rd&amp;quot;, &amp;quot;FinalChoice&amp;quot;))
x&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## This is first this issecond           3rd   FinalChoice 
##             1             2             3             4&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;names(x) &amp;lt;- make_clean_names(names(x)) # `x` is added to names that start with number
x&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## this_is_first this_issecond          x3rd  final_choice 
##             1             2             3             4&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;div id=&#34;tabyl-function&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;&lt;code&gt;tabyl()&lt;/code&gt; function&lt;/h3&gt;
&lt;p&gt;This function is an alternative to the &lt;code&gt;table()&lt;/code&gt; function from base-R. The function generate a frequency table from either a dataframe or vector.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;studynames &amp;lt;- messy_penguins %&amp;gt;%  clean_names() %&amp;gt;% 
                tabyl(study_name) # %&amp;gt;% 
                #adorn_pct_formatting(digits = 0, affix_sign = TRUE) # creates a percentage column

studynames&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##  study_name   n   percent
##     PAL0708 110 0.3197674
##     PAL0809 114 0.3313953
##     PAL0910 120 0.3488372&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;After &lt;code&gt;tabyl()&lt;/code&gt; function, we can use the janitor’s family of adorn_functions to format the resultant dataframes.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;studynames &amp;lt;- messy_penguins %&amp;gt;%  clean_names() %&amp;gt;% 
                tabyl(study_name) %&amp;gt;% 
                adorn_pct_formatting(digits = 0, affix_sign = TRUE) %&amp;gt;%  # format the percentage column
                adorn_totals(where = &amp;quot;row&amp;quot;) #%&amp;gt;%  #Add totals 


studynames&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##  study_name   n percent
##     PAL0708 110     32%
##     PAL0809 114     33%
##     PAL0910 120     35%
##       Total 344       -&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Other adorn functions are :&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;code&gt;adorn_pct_formatting&lt;/code&gt; Format a data.frame of decimals as percentages&lt;/li&gt;
&lt;li&gt;&lt;code&gt;adorn_rounding&lt;/code&gt; Round the numeric columns in a data.frame&lt;/li&gt;
&lt;li&gt;&lt;code&gt;adorn_totals&lt;/code&gt; Add a totals row and/or column to a data.frame.&lt;/li&gt;
&lt;li&gt;&lt;code&gt;adorn_ns&lt;/code&gt; Add underlying Ns to a tabyl displaying percentages&lt;/li&gt;
&lt;/ul&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;mtcars %&amp;gt;%
  tabyl(am, cyl) %&amp;gt;% 
  adorn_percentages(&amp;quot;col&amp;quot;) %&amp;gt;% 
 adorn_totals(where = c(&amp;quot;row&amp;quot;,&amp;quot;col&amp;quot;)) %&amp;gt;% 
  adorn_pct_formatting(digits = 0) %&amp;gt;% 
  adorn_rounding(digits = 3) %&amp;gt;% 
  adorn_ns(position = &amp;quot;front&amp;quot;) # %&amp;gt;% &lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##     am         4        6         8     Total
##      0  3  (27%) 4  (57%) 12  (86%) 19 (170%)
##      1  8  (73%) 3  (43%)  2  (14%) 13 (130%)
##  Total 11 (100%) 7 (100%) 14 (100%) 32 (300%)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Let use compare with Base-R &lt;code&gt;table()&lt;/code&gt; function:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;tidy_names &amp;lt;- messy_penguins %&amp;gt;%  
                clean_names() 
              
table(tidy_names$study_name)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## 
## PAL0708 PAL0809 PAL0910 
##     110     114     120&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;If you have a vector, the function also works the same&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;Age &amp;lt;- c(23, 24, 24, 25, 23,26, 25)
tabyl(Age)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##  Age n   percent
##   23 2 0.2857143
##   24 2 0.2857143
##   25 2 0.2857143
##   26 1 0.1428571&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;div id=&#34;remove_empty&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;&lt;code&gt;remove_empty()&lt;/code&gt;&lt;/h3&gt;
&lt;p&gt;This functions usage is straight foward. It simply removes any colum/rows from a data.frame or matrix that contain all “NA” as their entries.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;empty &amp;lt;- messy_penguins %&amp;gt;% 
  remove_empty() # this will remove both empty rows and columns by default. &lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## value for &amp;quot;which&amp;quot; not specified, defaulting to c(&amp;quot;rows&amp;quot;, &amp;quot;cols&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;empty &amp;lt;- messy_penguins %&amp;gt;% 
  remove_empty(which = &amp;quot;rows&amp;quot;, quiet = TRUE) # specify row or column and use quite argument to supress  messages be suppressed (TRUE) or printed (FALSE) indicating the summary of empty columns or rows removed?&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;div id=&#34;remove-constant&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;&lt;code&gt;remove-constant()&lt;/code&gt;&lt;/h3&gt;
&lt;p&gt;Sometimes, we may need to find columns that have the same values, we can use &lt;code&gt;remove-constant()&lt;/code&gt; to to do that.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;data.frame(A=1, B=1:3, c= c(3,3,3))  &lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##   A B c
## 1 1 1 3
## 2 1 2 3
## 3 1 3 3&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;data.frame(A=1, B=1:3, c= c(3,3,3)) %&amp;gt;%  
dplyr::select_at(setdiff(names(.), names(remove_constant(.)))) %&amp;gt;%unique()&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##   A c
## 1 1 3&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;div id=&#34;get_dupes-to-remove-duplicates&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;&lt;code&gt;get_dupes()&lt;/code&gt; to Remove duplicates&lt;/h3&gt;
&lt;p&gt;Sometimes our data may contains duplicates that we may not like. So, we need to find and possibly remove them if any. &lt;code&gt;get_dupes()&lt;/code&gt; returns a records (and inserts a count of duplicates) so that we can deal with identfied cases accordingly.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;messy_penguins %&amp;gt;% 
  clean_names() %&amp;gt;% 
  get_dupes() # This dataset no any duplicate.&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## No variable names specified - using all columns.&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## No duplicate combinations found of: study_name, sample_number, species, region, island, stage, individual_id, clutch_completion, date_egg, ... and 9 other variables&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## # A tibble: 0 x 19
## # … with 19 variables: study_name &amp;lt;chr&amp;gt;, sample_number &amp;lt;dbl&amp;gt;, species &amp;lt;chr&amp;gt;,
## #   region &amp;lt;chr&amp;gt;, island &amp;lt;chr&amp;gt;, stage &amp;lt;chr&amp;gt;, individual_id &amp;lt;chr&amp;gt;,
## #   clutch_completion &amp;lt;chr&amp;gt;, date_egg &amp;lt;chr&amp;gt;, culmen_length_mm &amp;lt;chr&amp;gt;,
## #   nickname &amp;lt;chr&amp;gt;, culmen_depth_mm &amp;lt;chr&amp;gt;, flipper_length_mm &amp;lt;chr&amp;gt;,
## #   body_mass &amp;lt;chr&amp;gt;, sex &amp;lt;chr&amp;gt;, delta_15_n_o_oo &amp;lt;chr&amp;gt;, delta_13_c_o_oo &amp;lt;chr&amp;gt;,
## #   comments &amp;lt;chr&amp;gt;, dupe_count &amp;lt;int&amp;gt;&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Tip: call clean_names() every time you read in a new data set to automatically clean column names.&lt;/p&gt;
&lt;style&gt;
body {
text-align: justify}
&lt;/style&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&#34;footnotes&#34;&gt;
&lt;hr /&gt;
&lt;ol&gt;
&lt;li id=&#34;fn1&#34;&gt;&lt;p&gt;&lt;a href=&#34;https://vita.had.co.nz/papers/tidy-data.pdf&#34;&gt;Tidy Data : Hadley Wikham&lt;/a&gt;&lt;a href=&#34;#fnref1&#34; class=&#34;footnote-back&#34;&gt;↩︎&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li id=&#34;fn2&#34;&gt;&lt;p&gt;&lt;a href=&#34;https://cran.r-project.org/web/packages/janitor/vignettes/janitor.html&#34;&gt;The janitor package&lt;/a&gt;&lt;a href=&#34;#fnref2&#34; class=&#34;footnote-back&#34;&gt;↩︎&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li id=&#34;fn3&#34;&gt;&lt;p&gt;&lt;a href=&#34;https://dplyr.tidyverse.org/&#34;&gt;dplyr the grammar of data manipulation&lt;/a&gt;&lt;a href=&#34;#fnref3&#34; class=&#34;footnote-back&#34;&gt;↩︎&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li id=&#34;fn4&#34;&gt;&lt;p&gt;&lt;a href=&#34;https://tidyr.tidyverse.org/articles/tidy-data.html&#34;&gt;Tidyr&lt;/a&gt;&lt;a href=&#34;#fnref4&#34; class=&#34;footnote-back&#34;&gt;↩︎&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>Weekly Meeting</title>
      <link>https://hausanlp.github.io/event/example/</link>
      <pubDate>Sun, 27 Dec 2020 09:00:00 +0000</pubDate>
      <guid>https://hausanlp.github.io/event/example/</guid>
      <description>&lt;!---
#Slides can be added in a few ways:

#- **Create** slides using Wowchemy&#39;s #[*Slides*](https://wowchemy.com/docs/managing-content/#create-sli#des) feature and link using `slides` parameter in the front #matter of the talk file
#- **Upload** an existing slide deck to `static/` and link using #`url_slides` parameter in the front matter of the talk file
#- **Embed** your slides (e.g. Google Slides) or presentation #video on this page using #[shortcodes](https://wowchemy.com/docs/writing-markdown-latex/).

#Further event details, including page elements such as image #galleries, can be added to the body of this page.
--&gt;&lt;blockquote&gt;
&lt;/blockquote&gt;
</description>
    </item>
    
    <item>
      <title>Using Self-Training to Improve Back-Translation in Low Resource Neural Machine Translation</title>
      <link>https://hausanlp.github.io/publication/abdulmumin-2020-aa/</link>
      <pubDate>Mon, 01 Jun 2020 00:00:00 +0000</pubDate>
      <guid>https://hausanlp.github.io/publication/abdulmumin-2020-aa/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Participatory Research for Low-resourced Machine Translation: A Case Study in African Languages</title>
      <link>https://hausanlp.github.io/publication/nekoto-2020-participatory/</link>
      <pubDate>Wed, 01 Jan 2020 00:00:00 +0000</pubDate>
      <guid>https://hausanlp.github.io/publication/nekoto-2020-participatory/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Tag-less Back-Translation</title>
      <link>https://hausanlp.github.io/publication/abdulmumin-2019-ab/</link>
      <pubDate>Sun, 01 Dec 2019 00:00:00 +0000</pubDate>
      <guid>https://hausanlp.github.io/publication/abdulmumin-2019-ab/</guid>
      <description></description>
    </item>
    
    <item>
      <title>hauWE: Hausa Words Embedding for Natural Language Processing</title>
      <link>https://hausanlp.github.io/publication/abdulmumin-2019-aa/</link>
      <pubDate>Fri, 01 Nov 2019 00:00:00 +0000</pubDate>
      <guid>https://hausanlp.github.io/publication/abdulmumin-2019-aa/</guid>
      <description></description>
    </item>
    
    <item>
      <title>An example preprint / working paper</title>
      <link>https://hausanlp.github.io/publications/preprint/</link>
      <pubDate>Sun, 07 Apr 2019 00:00:00 +0000</pubDate>
      <guid>https://hausanlp.github.io/publications/preprint/</guid>
      <description>&lt;p&gt;Supplementary notes can be added here, including &lt;a href=&#34;https://sourcethemes.com/academic/docs/writing-markdown-latex/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;code and math&lt;/a&gt;.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Hausa Corpus</title>
      <link>https://hausanlp.github.io/project/hausacorpus/</link>
      <pubDate>Wed, 27 Apr 2016 00:00:00 +0000</pubDate>
      <guid>https://hausanlp.github.io/project/hausacorpus/</guid>
      <description>&lt;p&gt;This&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Hausa Machine Translation</title>
      <link>https://hausanlp.github.io/project/hausatranslation/</link>
      <pubDate>Wed, 27 Apr 2016 00:00:00 +0000</pubDate>
      <guid>https://hausanlp.github.io/project/hausatranslation/</guid>
      <description>&lt;p&gt;This&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Hausa Speech Recognition</title>
      <link>https://hausanlp.github.io/project/hausaspeech/</link>
      <pubDate>Wed, 27 Apr 2016 00:00:00 +0000</pubDate>
      <guid>https://hausanlp.github.io/project/hausaspeech/</guid>
      <description>&lt;p&gt;This&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Sentiment Analysis</title>
      <link>https://hausanlp.github.io/project/sanalysis/</link>
      <pubDate>Wed, 27 Apr 2016 00:00:00 +0000</pubDate>
      <guid>https://hausanlp.github.io/project/sanalysis/</guid>
      <description>&lt;p&gt;This&lt;/p&gt;
&lt;h1 id=&#34;---&#34;&gt;&amp;mdash;&lt;/h1&gt;
&lt;h1 id=&#34;date-2020-02-27t0000000100&#34;&gt;date: &amp;ldquo;2020-02-27T00:00:00+01:00&amp;rdquo;&lt;/h1&gt;
&lt;h1 id=&#34;external_link-&#34;&gt;external_link: &amp;quot;&amp;quot;&lt;/h1&gt;
&lt;h1 id=&#34;image&#34;&gt;image:&lt;/h1&gt;
&lt;h1 id=&#34;caption-&#34;&gt;caption: &amp;quot;&amp;quot;&lt;/h1&gt;
&lt;h1 id=&#34;focal_point-smart&#34;&gt;focal_point: Smart&lt;/h1&gt;
&lt;h1 id=&#34;links&#34;&gt;#links:&lt;/h1&gt;
&lt;h1 id=&#34;--icon-twitter&#34;&gt;#- icon: twitter&lt;/h1&gt;
&lt;h1 id=&#34;-icon_pack-fab&#34;&gt;# icon_pack: fab&lt;/h1&gt;
&lt;h1 id=&#34;--name-follow&#34;&gt;#  name: Follow&lt;/h1&gt;
&lt;h1 id=&#34;-url-httpstwittercomgeorgecushen&#34;&gt;# url: &lt;a href=&#34;https://twitter.com/georgecushen&#34;&gt;https://twitter.com/georgecushen&lt;/a&gt;&lt;/h1&gt;
&lt;h1 id=&#34;slides-example-slides&#34;&gt;#slides: example-slides&lt;/h1&gt;
&lt;h1 id=&#34;summary-this-project-aims-to-develop-hausa-language-resource-for-natural-language-processing-task-such-as-hausa-social-media-corpus-hausa-sentiment-lexicon--hausaner--and-pos&#34;&gt;summary: This project aims to develop Hausa language resource for natural language processing task such as Hausa Social Media Corpus, Hausa Sentiment Lexicon , HausaNER , and POS.&lt;/h1&gt;
&lt;h1 id=&#34;tags&#34;&gt;tags:&lt;/h1&gt;
&lt;h1 id=&#34;--nlp&#34;&gt;- NLP&lt;/h1&gt;
&lt;h1 id=&#34;title-hausa-text-classification&#34;&gt;title: Hausa Text Classification&lt;/h1&gt;
&lt;h1 id=&#34;url_code&#34;&gt;url_code:&lt;/h1&gt;
&lt;h1 id=&#34;url_pdf-&#34;&gt;url_pdf: &amp;quot;&amp;quot;&lt;/h1&gt;
&lt;h1 id=&#34;url_slides-&#34;&gt;url_slides: &amp;quot;&amp;quot;&lt;/h1&gt;
&lt;h1 id=&#34;url_video-&#34;&gt;url_video: &amp;quot;&amp;quot;&lt;/h1&gt;
&lt;h1 id=&#34;----1&#34;&gt;&amp;mdash;&lt;/h1&gt;
&lt;h1 id=&#34;heading&#34;&gt;&lt;/h1&gt;
&lt;h1 id=&#34;this-project-involves-people-that-are-interested-in-hausa-text-classification-task-such-as-sentiment-analysis&#34;&gt;This project involves people that are interested in Hausa text classification task such as sentiment analysis.&lt;/h1&gt;
&lt;h1 id=&#34;heading-1&#34;&gt;&lt;/h1&gt;
&lt;h1 id=&#34;heading-2&#34;&gt;&lt;/h1&gt;
&lt;h1 id=&#34;style&#34;&gt;&lt;style&gt;&lt;/h1&gt;
&lt;h1 id=&#34;body-&#34;&gt;body {&lt;/h1&gt;
&lt;h1 id=&#34;text-align-justify&#34;&gt;text-align: justify}&lt;/h1&gt;
&lt;h1 id=&#34;style-1&#34;&gt;&lt;/style&gt;&lt;/h1&gt;
&lt;h1 id=&#34;heading-3&#34;&gt;&lt;/h1&gt;
</description>
    </item>
    
    <item>
      <title>An example journal article</title>
      <link>https://hausanlp.github.io/publications/journal-article/</link>
      <pubDate>Tue, 01 Sep 2015 00:00:00 +0000</pubDate>
      <guid>https://hausanlp.github.io/publications/journal-article/</guid>
      <description>&lt;div class=&#34;alert alert-note&#34;&gt;
  &lt;div&gt;
    Click the &lt;em&gt;Cite&lt;/em&gt; button above to demo the feature to enable visitors to import publication metadata into their reference management software.
  &lt;/div&gt;
&lt;/div&gt;
&lt;p&gt;Supplementary notes can be added here, including &lt;a href=&#34;https://sourcethemes.com/academic/docs/writing-markdown-latex/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;code and math&lt;/a&gt;.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Text normalization algorithm for facebook chats in hausa language</title>
      <link>https://hausanlp.github.io/publication/maitama-2014-text/</link>
      <pubDate>Wed, 01 Jan 2014 00:00:00 +0000</pubDate>
      <guid>https://hausanlp.github.io/publication/maitama-2014-text/</guid>
      <description>&lt;p&gt;The rapid increase in using non-standard words (NSWs) in communication through the social media is causing difficulties in understanding contents of the text messages. In addition, it affects the performance of several natural language processing (NLP) task such as machine translation, information retrievals, summarization and etc. In this study, we present an automatic text normalization system on Facebook chatting based on Hausa language. The proposed algorithm manually developed dictionary that employ normalization of each non-standard word with its equivalent standard word. This is accomplished through modification of the technique employed by [1] to fit Hausa NSWs&#39; formation. It was found that our proposed algorithm was able to normalized Hausa NSWs with an accuracy of 100%The results of this research can facilitate comprehensive communication via Facebook using Hausa language.&lt;/p&gt;
&lt;style&gt;
body {
text-align: justify}
&lt;/style&gt;
</description>
    </item>
    
    <item>
      <title>An example conference paper</title>
      <link>https://hausanlp.github.io/publications/conference-paper/</link>
      <pubDate>Mon, 01 Jul 2013 00:00:00 +0000</pubDate>
      <guid>https://hausanlp.github.io/publications/conference-paper/</guid>
      <description>&lt;div class=&#34;alert alert-note&#34;&gt;
  &lt;div&gt;
    Click the &lt;em&gt;Cite&lt;/em&gt; button above to demo the feature to enable visitors to import publication metadata into their reference management software.
  &lt;/div&gt;
&lt;/div&gt;
&lt;p&gt;Supplementary notes can be added here, including &lt;a href=&#34;https://sourcethemes.com/academic/docs/writing-markdown-latex/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;code and math&lt;/a&gt;.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title></title>
      <link>https://hausanlp.github.io/contact/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://hausanlp.github.io/contact/</guid>
      <description></description>
    </item>
    
    <item>
      <title></title>
      <link>https://hausanlp.github.io/people/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://hausanlp.github.io/people/</guid>
      <description></description>
    </item>
    
  </channel>
</rss>

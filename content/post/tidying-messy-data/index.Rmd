---
title: How to Tidy Messy Data  Part 1)
date: 2021-01-09
draft: false
authors:
- admin
tags:
- Rstats
- Data Science
featured: false
# Featured image
# To use, add an image named `featured.jpg/png` to your page's folder.
# Placement options: 1 = Full column width, 2 = Out-set, 3 = Screen-width
# Focal point options: Smart, Center, TopLeft, Top, TopRight, Left, Right, BottomLeft, Bottom, BottomRight
image:
  placement: 3gi
  caption: 'Why Blog'
  focal_point: "Smart"
  preview_only: true
---

Data scientist often spent about 80% of data analysis process on cleaning and preparing data[^1]. Worst still, cleaning and preparing the data is an iterative process. Hadley Wickham refer to this process of cleaning and preparing data as **data tidying**: structuring datasets to facilitate analysis. Therefore, it is very important to get the right tool to efficiently and quickly tidy any messy data and spend more time working on your analysis.

[^1]: [Tidy Data : Hadley Wikham](https://vita.had.co.nz/papers/tidy-data.pdf)

<center>
![Tidydata](tidydata.png)
</center>

I mostly use Python for machine learning. But R is an exceptional tool for data manipulation, data visualization, and data analysis due to the many available packages in R developed mainly for data analysis. R is becoming the "de facto best tool" for data analysis. Therefore, we will use R to explore different ways to tidy data. In this part 1 series, we will gently start by exploring the `Janitor`[^2] package and see how it makes tidying data easy. In subsequent series, we will explore `dplyr`[^3] and `tidyr`[^4] packages which are the most complete packages for data manipulaton and tidying data.

[^2]: [The janitor package](https://cran.r-project.org/web/packages/janitor/vignettes/janitor.html)

[^3]: [dplyr the grammar of data manipulation](https://dplyr.tidyverse.org/)

[^4]: [Tidyr](https://tidyr.tidyverse.org/articles/tidy-data.html)


<center>
![R Vs Python ](rpython.jpg)
</center>

## Janitor Package

The janitor package has user-friendly functions for tidying messy data. It provides functions for formating column names, detecting duplicate records, provide quick tabulations, and many more.

For the purpose of this series, we are going to use a [pinguin dataset](https://github.com/BrunoGrandePhD/2020-11-14-rladies-workshop/blob/main/learnr-tutorial/messy_penguins.cs) that has been deliberately messed. 

Loading the required packages

```{r message=FALSE, warning=FALSE}
library(janitor)                                                     # CRAN v2.1.0
library(tidyverse)                                                   # CRAN v1.3.0
```

Loading the dataset from [Github](%22https://raw.githubusercontent.com/BrunoGrandePhD/2020-11-14-rladies-workshop/rladies-tunis/learnr-tutorial/messy_penguins.csv).

```{r message=FALSE, warning=FALSE}

messy_penguins <- read_csv("https://raw.githubusercontent.com/BrunoGrandePhD/2020-11-14-rladies-workshop/rladies-tunis/learnr-tutorial/messy_penguins.csv")
```

Observing the data

```{r}
glimpse(messy_penguins)
```

### `clean_names()` function

The `clean_names()` handles problematic variable names, returning only lowercase letters with underscore as separator, appends numbers to duplicated names, andles special characters and spaces, and converts "%" to "percent" to retain meaning. clean_names() can only be use on dataframe like objects, other objects such as named lists and vectors, `make_clean_names()` is used.

Let us observe column names for our messy data

```{r}
colnames(messy_penguins)

```

We can see that, the column names structure is not uniform ( e.g "studyName", "Sample Number", "Delta 15 N (o/oo)"). So, to tidy these column names, we can use the `clean_names()` function to change them to uniform structure.

```{r}
tidy_penguins <- clean_names(messy_penguins) 

colnames(tidy_penguins)
    
```

Now, all the column names are change to lower-case and have consistent structure. By default, `clean_names()` return snake-case like names, but you can specify other options such as the following cases:

-   snake_case: "snake"
-   lowerCamel: "lower_camel" or "small_camel"
-   UpperCamel: "upper_camel" or "big_camel"
-   ALL_CAPS: "all_caps" or "screaming_snake"
-   lowerUPPER: "lower_upper"
-   UPPERlower: "upper_lower"
-   Sentence case: "sentence"
-   Title Case: "title"

You can get details about any case [here](https://rdrr.io/cran/snakecase/man/to_any_case.html)

```{r}

messy_penguins %>%  
  clean_names(case ="lower_camel") %>% 
   colnames()

```

To clean names, but leave some abbreviations to appear the way you want.

```{r}

messy_penguins %>% 
      clean_names(case = "lower_camel",  abbreviations = c("ID", "N", "mm")) %>% 
     colnames()



```

You can also restore column names to Title Case, e.g., for plotting

```{r}

tidy_penguins %>%  
  clean_names( case = "title") %>% 
   colnames()


```

For vectors, we can use `make_clean_names` functions.

```{r}
x <- structure(1:4, names = c("This is first", "this issecond", "3rd", "FinalChoice"))
x
```



```{r}

names(x) <- make_clean_names(names(x)) # `x` is added to names that start with number
x
```



### `tabyl()` function

This function is an alternative to the `table()` function from base-R. The function generate a frequency table from either a dataframe or vector.

```{r}
studynames <- messy_penguins %>%  clean_names() %>% 
                tabyl(study_name) # %>% 
                #adorn_pct_formatting(digits = 0, affix_sign = TRUE) # creates a percentage column

studynames

```

After `tabyl()` function, we can use the janitor's family of adorn_functions to format the resultant dataframes.

```{r}
studynames <- messy_penguins %>%  clean_names() %>% 
                tabyl(study_name) %>% 
                adorn_pct_formatting(digits = 0, affix_sign = TRUE) %>%  # format the percentage column
                adorn_totals(where = "row") #%>%  #Add totals 


studynames

```

Other adorn functions are :

-   `adorn_pct_formatting` Format a data.frame of decimals as percentages
-   `adorn_rounding` Round the numeric columns in a data.frame
-   `adorn_totals` Add a totals row and/or column to a data.frame.
-   `adorn_ns` Add underlying Ns to a tabyl displaying percentages


```{r}
mtcars %>%
  tabyl(am, cyl) %>% 
  adorn_percentages("col") %>% 
 adorn_totals(where = c("row","col")) %>% 
  adorn_pct_formatting(digits = 0) %>% 
  adorn_rounding(digits = 3) %>% 
  adorn_ns(position = "front") # %>% 
```

Let use compare with Base-R `table()` function:

```{r}
tidy_names <- messy_penguins %>%  
                clean_names() 
              
table(tidy_names$study_name)
```

If you have a vector, the function also works the same

```{r}
Age <- c(23, 24, 24, 25, 23,26, 25)
tabyl(Age)
```

### `remove_empty()`

This functions usage is straight foward. It simply removes any colum/rows from a data.frame or matrix that contain all "NA" as their entries.

```{r}
empty <- messy_penguins %>% 
  remove_empty() # this will remove both empty rows and columns by default. 


empty <- messy_penguins %>% 
  remove_empty(which = "rows", quiet = TRUE) # specify row or column and use quite argument to supress  messages be suppressed (TRUE) or printed (FALSE) indicating the summary of empty columns or rows removed?
```

### `remove-constant()`

Sometimes, we may need to find columns that have the same values, we can use `remove-constant()` to to do that.

```{r}
data.frame(A=1, B=1:3, c= c(3,3,3))  
           
```

```{r}
data.frame(A=1, B=1:3, c= c(3,3,3)) %>%  
dplyr::select_at(setdiff(names(.), names(remove_constant(.)))) %>%unique()
```

### `get_dupes()` to Remove duplicates

Sometimes our data may contains duplicates that we may not like. So, we need to find and possibly remove them if any. `get_dupes()` returns a records (and inserts a count of duplicates) so that we can deal with identfied cases accordingly.

```{r}
messy_penguins %>% 
  clean_names() %>% 
  get_dupes() # This dataset no any duplicate.
```


Tip: call clean_names() every time you read in a new data set to automatically clean column names.

<style>
body {
text-align: justify}
</style>



